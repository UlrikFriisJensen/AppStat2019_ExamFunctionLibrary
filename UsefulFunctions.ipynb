{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions for Applied Statistics Exam\n",
    "***\n",
    "### Authors:\n",
    " - Ulrik Friis-Jensen (lgb543@alumni.ku.dk)\n",
    " \n",
    "### Co-authors:\n",
    " - Christian Noes Petersen (lbc622@alumni.ku.dk)\n",
    " - David Harding-Larsen (pfl888@alumni.ku.dk)\n",
    " - Lars Erik Skjegstad (zfj803@alumni.ku.dk)\n",
    " - Marcus Frahm Nygaard (nwb154@alumni.ku.dk)\n",
    " - Lasse Skjoldborg Krog (cxq235@alumni.ku.dk)\n",
    "\n",
    "### Date:\n",
    " - Exam 2019 version from 15-01-2020\n",
    " - Latest update: 19-01-2020\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<a id='contents'></a>\n",
    "### Imports\n",
    " - [Useful imports](#imports)\n",
    " \n",
    "### Functions for $\\chi^2$\n",
    " - [Constant](#constant)\n",
    " - [Linear](#linear)\n",
    " - [2nd degree polynomial](#poly_2)\n",
    " - [3rd degree polynomial](#poly_3)\n",
    " - [Binomial](#binomial)\n",
    " - [Poisson](#poisson)\n",
    " - [Gaussian](#gaussian)\n",
    " - [Double Gaussian](#gaussian_x2)\n",
    " - [Triple Gaussian](#gaussian_x3)\n",
    " - [Exponential decay](#exp_decay)\n",
    " - [Exponential growth](#exp_growth)\n",
    " - [Sigmoid](#sigmoid)\n",
    " \n",
    "### Simple functions\n",
    " - [Gaussian probability for a sigma interval](#gauss_prob)\n",
    " - [Determine tail containing a certain gaussian probability](#gauss_percentile)\n",
    " - [Mean of measurements w/o uncertainties](#mean_no_unc)\n",
    " - [Put data into bins](#bin_data)\n",
    "\n",
    "### Advanced functions\n",
    " - [$\\chi^2$-test for uniform distribution of histogram](#chi2_test_uni)\n",
    " - [Pearson's $\\chi^2$-test](#pearsons_chi2)\n",
    " - [Kolmogorov-Smirnov comparison of two histograms](#ks_comp)\n",
    " - [Kolmogorov-Smirnov test](#ks_test)\n",
    " - [General $\\chi^2$-fit](#chi2_fit)\n",
    " - [Unbinned likelihood regression](#ublh_reg)\n",
    " - [Log likelihood sweep](#log_lh_sweep)\n",
    " - [Monte Carlo generation of random numbers](#monte_carlo)\n",
    " - [Array of sums of Monte Carlo generated numbers](#mc_sums)\n",
    " - [MC simulation of error propagation](#mc_error)\n",
    " - [Correlation matrix](#corr_matrix)\n",
    " - [Seperation of histograms](#calc_sep)\n",
    " - [ROC curve from two histograms](#calc_roc)\n",
    " - [Covariance of off-diagonal element in covariance matrix](#covar_offdiag)\n",
    " - [Covariance matrix](#covar_matrix)\n",
    " - [Fisher coefficients](#fisher_coef)\n",
    " - [Fisher discriminants](#fisher_descri)\n",
    " \n",
    "### Useful functions from other packages\n",
    " - [Basic statistical functions](#dist_func)\n",
    " - [Other useful functions](#other_func)\n",
    "\n",
    "### Plotting template\n",
    " - [Template](#plotting_template)\n",
    " - [Common plots](#common_plots)\n",
    " - [Common formatting](#common_format)\n",
    " - [Save plots to common filetypes](#common_save)\n",
    " - [Inspiration for plotting](#plot_inspiration)\n",
    " \n",
    "### Integration of the External_Functions package\n",
    " - [Functions from the package](#external_functions)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "[To the Table of Contents](#contents)\n",
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt                        \n",
    "import seaborn as sns                                  \n",
    "from iminuit import Minuit                             \n",
    "import sys   \n",
    "from scipy import stats\n",
    "\n",
    "# To import the functions in this file\n",
    "# sys.path.append('../Useful_Functions')\n",
    "# import UsefulFunctions as uf\n",
    "\n",
    "\n",
    "plt.rcParams['font.size'] = 18  \n",
    "\n",
    "# r = np.random\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for $\\chi^2$\n",
    "[To the Table of Contents](#contents)\n",
    "<a id='constant'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant(x, const):\n",
    "    return const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linear'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, x0, x1):\n",
    "    return x1 * x + x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='poly_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_2(x, x0, x1, x2):\n",
    "    return x2* x**2 + x1 * x + x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='poly_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_3(x, x0, x1, x2, x3):\n",
    "    return x3 * x**3 + x2 * x**2 + x1 * x + x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='binomial'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial(x, n, p, N = 1):\n",
    "    return N * stats.binom.pmf(x,n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='poisson'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson(x, mu, N = 1, binwidth = 1.0) :\n",
    "    return binwidth * N * stats.poisson.pmf(x, mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gaussian'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, N = 1.0, mu = 0.0, sigma = 1.0, binwidth = 1.0) :\n",
    "    return binwidth * N * stats.norm.pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gaussian_x2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_x2(x, N1, mu1, sigma1, N2, mu2, sigma2, binwidth1 = 1.0, binwidth2 = 1.0):\n",
    "    return gaussian(x, N1, mu1, sigma1, binwidth=binwidth1) + gaussian(x, N2, mu2, sigma2, binwidth=binwidth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gaussian_x3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_x3(x, N1, mu1, sigma1, N2, mu2, sigma2, N3, mu3, sigma3, binwidth1 = 1.0, binwidth2 = 1.0, binwidth3 = 1.0):\n",
    "    return gaussian(x, N1, mu1, sigma1, binwidth=binwidth1) + gaussian(x, N2, mu2, sigma2, binwidth=binwidth2) + gaussian(x, N3, mu3, sigma3, binwidth=binwidth3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp_decay'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(x, C, k):\n",
    "    return C * np.exp(-x/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp_growth'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_growth(x, C, k):\n",
    "    return C * np.exp(x/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sigmoid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L, x0):\n",
    "    return L * ((x - x0) / np.sqrt(1 + (x - x0)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple functions\n",
    "[To the Table of Contents](#contents)\n",
    "<a id='gauss_prob'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_prob(sig1, sig2, mu=0, sig=1, two_tailed=True):\n",
    "    '''\n",
    "    Calculates the probability for a gaussian value to lie\n",
    "    in a specified interval of sigmas away from the mean.\n",
    "    '''\n",
    "    prob1 = stats.norm.sf(sig1, loc=mu, scale=sig)\n",
    "    prob2 = stats.norm.sf(sig2, loc=mu, scale=sig)\n",
    "    if two_tailed:\n",
    "        prob = 2 * (prob1 - prob2)\n",
    "        print(f'Probability (two tailed) for a Gaussian value to lie between {sig1} and {sig2} sigma away from the mean: {prob:.2%}')\n",
    "    else:\n",
    "        prob = prob1 - prob2\n",
    "        print(f'Probability (one tailed) for a Gaussian value to lie between {sig1} and {sig2} sigma away from the mean: {prob:.2%}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gauss_percentile'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_percentile(prob, mu=0, sig=1, digits=3, tail=1, return_values=False):\n",
    "    '''\n",
    "    Determines the value of a gaussianly distributed variable at which the integral \n",
    "    from the variable and away from the mean is equal to a given percentile.\n",
    "    \n",
    "    If no input for mu and sig is given the result is returned in sigma away from the mean.\n",
    "    \n",
    "    The optional argument tail determines if the value(s) are for the lower tail, higher tail or both.\n",
    "      - 0 is lower tail\n",
    "      - 1 is upper tail (default)\n",
    "      - 2 is both tails\n",
    "    '''\n",
    "    result = None\n",
    "    \n",
    "    if tail==0:\n",
    "        lower_val = stats.norm.ppf(prob, loc=mu, scale=sig)\n",
    "        print(f'The lower tail contains {prob:.1%} if the integral is taken from {lower_val:.{digits}f} and down.')\n",
    "        if return_values: result = lower_val\n",
    "        return result\n",
    "    \n",
    "    if tail==1:\n",
    "        upper_val = stats.norm.isf(prob, loc=mu, scale=sig)\n",
    "        print(f'The upper tail contains {prob:.1%} if the integral is taken from {upper_val:.{digits}f} and up.')\n",
    "        if return_values: result = upper_val\n",
    "        return result\n",
    "    \n",
    "    if tail==2:\n",
    "        lower_val = stats.norm.ppf(prob/2, loc=mu, scale=sig)\n",
    "        upper_val = stats.norm.isf(prob/2, loc=mu, scale=sig)\n",
    "        print(f'The two tails contains {prob:.1%} combined if the integral is taken from {lower_val:.{digits}f} and down and from {upper_val:.{digits}f} and up.')\n",
    "        if return_values: result = np.array([lower_val, upper_val])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mean_no_unc'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_no_unc(data, digits=4,get_values=False):\n",
    "    '''\n",
    "    Calculates the mean, RMS and uncertainty on mean for a data sample w/o uncertainties.\n",
    "    '''\n",
    "    mean = data.mean()\n",
    "    unc_on_data = np.sqrt(np.sum((data-mean)**2)/(len(data)-1))\n",
    "    unc_on_mean = unc_on_data / np.sqrt(len(data))\n",
    "    print(f'''\n",
    "    ____________________________________________________\n",
    "    ----------------------------------------------------\n",
    "    Mean of data set:  {mean:.{digits}f} +/- {unc_on_mean:.{digits}f} (RMS = {unc_on_data:.{digits}f})\n",
    "    ____________________________________________________''')\n",
    "    if get_values:\n",
    "        return mean, unc_on_data, unc_on_mean\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bin_data'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(data, Nbins, xmin, xmax):\n",
    "    '''\n",
    "    Converts a list or array to a histogram.\n",
    "    Returns bin_centers, counts, error on counts and binwidth.\n",
    "    '''\n",
    "    counts, bin_edges = np.histogram(data, bins=Nbins, range=(xmin, xmax))\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "    s_counts = np.sqrt(counts) \n",
    "    \n",
    "    x = bin_centers[counts>0]\n",
    "    y = counts[counts>0]\n",
    "    sy = s_counts[counts>0]\n",
    "    \n",
    "    binwidth = (xmax-xmin) / Nbins\n",
    "    return x, y, sy, binwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced functions\n",
    "[To the Table of Contents](#contents)\n",
    "<a id='chi2_test_uni'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_test_uniform(bin_centers, counts, get_values=False):\n",
    "    '''\n",
    "    Tests if a histogram is uniformly distributed.\n",
    "    '''\n",
    "    data = counts\n",
    "    expected = data.sum() / len(bin_centers)\n",
    "    chi2 = np.sum( (data - expected)**2 / data )\n",
    "    Ndof = len(bin_centers)-1\n",
    "    p_chi2 = stats.chi2.sf(chi2, Ndof) \n",
    "\n",
    "    print(f'''\n",
    "    _____________________________\n",
    "    -----------------------------\n",
    "    ChiSquare test (uniform dist)\n",
    "    -----------------------------\n",
    "    Chi2-value = {chi2:.3f}\n",
    "    Ndof       = {Ndof}\n",
    "    Chi2-prob  = {p_chi2:.2%}\n",
    "    _____________________________''')\n",
    "    if get_values:\n",
    "        return chi2, Ndof, p_chi2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pearsons_chi2'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsons_chi2(obs_counts, exp_counts_or_dist, use_dist=False, A_and_B = True, get_values=False):\n",
    "    '''\n",
    "    Pearson's ChiSquare test for comparing a histogram to another histogram or distribution.\n",
    "    Input arguments are the observed counts and the expected binomial/poisson.\n",
    "    \n",
    "    A_and_B determines if the denominator is A+B or just B.\n",
    "    '''  \n",
    "    chi2 = 0\n",
    "    events = 0\n",
    "    if use_dist:\n",
    "        exp_counts = obs_counts.sum()*exp_counts_or_dist\n",
    "    else:\n",
    "        exp_counts = exp_counts_or_dist\n",
    "        \n",
    "    for A, B in zip(obs_counts, exp_counts):\n",
    "        if A_and_B:\n",
    "            denom = A + B\n",
    "        else:\n",
    "            denom = B\n",
    "        if A != 0 and B != 0:\n",
    "            chi2 += (A - B)**2 / (denom)\n",
    "            events += 1\n",
    "\n",
    "    Ndof = events\n",
    "    p_chi2 = stats.chi2.sf(chi2, Ndof) \n",
    "\n",
    "    print(f'''\n",
    "    ___________________________\n",
    "    ---------------------------\n",
    "     Pearson's ChiSquare test\n",
    "    ---------------------------\n",
    "    Chi2-value = {chi2:.3f}\n",
    "    Ndof       = {Ndof}\n",
    "    Chi2-prob  = {p_chi2:.2%}\n",
    "    ___________________________''')\n",
    "    if get_values:\n",
    "        return chi2, Ndof, p_chi2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ks_comp'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_comparison(data1, data2, get_values=False, **kwdarg):\n",
    "    '''\n",
    "    Kolmogorov-Smirnov test for comparing to datasets.\n",
    "    Returns the test statistic, critical value and p-value either as a string or numbers.\n",
    "    Look at the documentation for scipy.stats.ks_comp for further details.\n",
    "    '''\n",
    "    D, p = stats.ks_2samp(data1, data2, **kwdarg)\n",
    "    d = D * np.sqrt(len(data1))\n",
    "    print(f'''\n",
    "    ____________________________________________________________\n",
    "    ------------------------------------------------------------\n",
    "    Result of Kolmogorov-Smirnov comparison between two datasets\n",
    "    ------------------------------------------------------------\n",
    "    KS statistic   :    {D:.4f}\n",
    "    Critical value :    {d:.4f}\n",
    "    p-value        :    {p:.2%}\n",
    "    ____________________________________________________________\n",
    "    ''')\n",
    "    if get_values:\n",
    "        return D, d, p\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ks_test'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(data1, cdf, get_values=False, **kwdarg):\n",
    "    '''\n",
    "    Kolmogorov-Smirnov test for comparing data to a continous distribution.\n",
    "    Returns the test statistic, critical value and p-value either as a string or numbers.\n",
    "    Look at the documentation for scipy.stats.ks_test for further details.\n",
    "    '''\n",
    "    D, p = stats.kstest(data1, cdf, **kwdarg)\n",
    "    d = D * np.sqrt(len(data1))\n",
    "    print(f'''\n",
    "    _____________________________________________\n",
    "    ---------------------------------------------\n",
    "          Result of Kolmogorov-Smirnov test\n",
    "    ---------------------------------------------\n",
    "    KS statistic   :    {D:.4f}\n",
    "    Critical value :    {d:.4f}\n",
    "    p-value        :    {p:.2%}\n",
    "    _____________________________________________\n",
    "    ''')\n",
    "    if get_values:\n",
    "        return D, d, p\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='chi2_fit'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_fit(func, x, y, yerr, get_values=False, print_result=True, pedantic = False, print_level = 0, digits=5, latex_format=False, **kwdarg):\n",
    "    '''\n",
    "    ChiSquare fit of a given function to a given data set.\n",
    "    \n",
    "    Returns the fitted parameters for further plotting.\n",
    "    \n",
    "    **kwdarg allows the user to specify initial parameter \n",
    "    values and fix values using the syntax from Minuit.\n",
    "    \n",
    "    The digits variable controls the amount of digits \n",
    "    given in the printed result.\n",
    "    \n",
    "    The latex_format command allows the user to generate a \n",
    "    table for latex with the fitted parameter values.\n",
    "    '''\n",
    "    chi2obj = Chi2Regression(func, x, y, yerr)\n",
    "    minuit_obj = Minuit(chi2obj, pedantic=pedantic, print_level=print_level, **kwdarg)\n",
    "\n",
    "    minuit_obj.migrad()   \n",
    "\n",
    "    if (not minuit_obj.get_fmin().is_valid) :                                   # Check if the fit converged\n",
    "        print(\"    WARNING: The ChiSquare fit DID NOT converge!!!\")\n",
    "\n",
    "    Chi2_value = minuit_obj.fval                                             # The Chi2 value\n",
    "    NvarModel = len(minuit_obj.args)\n",
    "    Ndof = len(x) - NvarModel\n",
    "    ProbChi2 = stats.chi2.sf(Chi2_value, Ndof)\n",
    "    if not print_result:\n",
    "        return minuit_obj.args, minuit_obj.errors\n",
    "    if latex_format:\n",
    "        print(r'''----------------------------------------------------------------------------------\n",
    "NB! This is not a perfect formatting.\n",
    "Units, caption, label and sometimes parameter names must be changed in LaTex.\n",
    "----------------------------------------------------------------------------------\n",
    "\n",
    "\\begin{table}[b]\n",
    "    \\centering\n",
    "    \\begin{tabular}{lrr}\n",
    "    \\hline\n",
    "    \\hline\n",
    "        Parameter & Value (Unit) & Unc. (Unit) \\\\\n",
    "    \\hline''')\n",
    "        for name in minuit_obj.parameters:\n",
    "            print(f'        ${name}$ & ${minuit_obj.values[name]:.{digits}f}$ & ${minuit_obj.errors[name]:.{digits}f}$ \\\\\\ ')\n",
    "        print(r'''    \\hline\n",
    "    \\hline''')\n",
    "        print(r'        $\\chi^2$-value = {0:.3f} & Ndof = {1} & $\\chi^2$-prob = {2:.3f} \\\\'.format(Chi2_value,Ndof,ProbChi2))\n",
    "        print(r'''    \\hline\n",
    "    \\hline\n",
    "    \\end{tabular}\n",
    "    \\caption{Results of $\\chi^2$-fit.}\n",
    "    \\label{tab:chi2_fit}\n",
    "\\end{table}''')\n",
    "    else:\n",
    "        print(f'''\n",
    "    _____________________________________________________\n",
    "    -----------------------------------------------------\n",
    "                    ChiSquare Fit Results\n",
    "    -----------------------------------------------------\n",
    "    Chi2-value = {Chi2_value:.3f}\n",
    "    Ndof       = {Ndof}\n",
    "    Chi2-prob  = {ProbChi2:.2%}\n",
    "    -----------------------------------------------------''')\n",
    "        for name in minuit_obj.parameters:\n",
    "            print(f'\\n    Chi2 Fit result:    {name} = {minuit_obj.values[name]:.{digits}f} +/- {minuit_obj.errors[name]:.{digits}f}')\n",
    "        print('    _____________________________________________________')\n",
    "    if get_values:\n",
    "        return minuit_obj.args, minuit_obj.errors, Chi2_value, Ndof, ProbChi2\n",
    "    else:\n",
    "        return minuit_obj.args, minuit_obj.errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ublh_reg'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnbinnedLH_reg(func, x, extended=True, pedantic = False, print_level = 0, digits=5, latex_format=False, **kwdarg):\n",
    "    '''\n",
    "    ChiSquare fit of a given function to a given data set.\n",
    "    \n",
    "    Returns the fitted parameters for further plotting.\n",
    "    \n",
    "    **kwdarg allows the user to specify initial parameter \n",
    "    values and fix values using the syntax from Minuit.\n",
    "    \n",
    "    The digits variable controls the amount of digits \n",
    "    given in the printed result.\n",
    "    \n",
    "    The latex_format command allows the user to generate a \n",
    "    table for latex with the fitted parameter values.\n",
    "    '''\n",
    "    ulreg = UnbinnedLH(func, x, extended = extended)\n",
    "    minuit_obj = Minuit(ulreg, pedantic=pedantic, print_level=print_level, **kwdarg)\n",
    "\n",
    "    minuit_obj.migrad()   \n",
    "\n",
    "    if (not minuit_obj.get_fmin().is_valid) :                                   # Check if the fit converged\n",
    "        print(\"    WARNING: The ChiSquare fit DID NOT converge!!!\")\n",
    "\n",
    "    if latex_format:\n",
    "        print(r'''----------------------------------------------------------------------------------\n",
    "NB! This is not a perfect formatting.\n",
    "Units, caption, label and sometimes parameter names must be changed in LaTex.\n",
    "----------------------------------------------------------------------------------\n",
    "\n",
    "\\begin{table}[b]\n",
    "    \\centering\n",
    "    \\begin{tabular}{lrr}\n",
    "    \\hline\n",
    "    \\hline\n",
    "        Parameter & Value (Unit) & Unc. (Unit) \\\\\n",
    "    \\hline''')\n",
    "        for name in minuit_obj.parameters:\n",
    "            print(f'        ${name}$ & ${minuit_obj.values[name]:.{digits}f}$ & ${minuit_obj.errors[name]:.{digits}f}$ \\\\\\ ')\n",
    "        print(r'''    \\hline\n",
    "    \\hline\n",
    "    \\hline\n",
    "    \\end{tabular}\n",
    "    \\caption{Results of unbinned likelihood regression.}\n",
    "    \\label{tab:ulreg}\n",
    "\\end{table}''')\n",
    "    else:\n",
    "        print(f'''\n",
    "    __________________________________________________________\n",
    "    ----------------------------------------------------------\n",
    "                 UnbinnedLH Regression Results\n",
    "    ----------------------------------------------------------''')\n",
    "        for name in minuit_obj.parameters:\n",
    "            print(f'\\n    UnbinnedLH reg. result:    {name} = {minuit_obj.values[name]:.{digits}f} +/- {minuit_obj.errors[name]:.{digits}f}')\n",
    "        print('    __________________________________________________________')\n",
    "    return minuit_obj.args, minuit_obj.errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log_lh_sweep'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_LH_sweep(data_list, log_func, N_steps, start, end, show_values = False, digits = 3):\n",
    "    '''\n",
    "    Log likelihood sweep of variable of choice\n",
    "    \n",
    "    Data list should be a 1D array\n",
    "    \n",
    "    log_func should be the logarithm of the pdf times -2,\n",
    "    as function of x and the variable of choice\n",
    "    \n",
    "    N_steps is number of steps in the sweep,\n",
    "    while start and end is the initial and final values of the sweep\n",
    "    \n",
    "    The digits variable controls the amount of digits given in the printed result.\n",
    "    '''\n",
    "    ullh_minval = 999999.9\n",
    "    ullh_minpos = 0.0\n",
    "    step = (end-start) / N_steps\n",
    "\n",
    "    ullh = np.zeros(N_steps+1)\n",
    "    var  = np.zeros(N_steps+1)\n",
    "\n",
    "    for i in range(N_steps+1):\n",
    "        var_hypo = start + i*step         \n",
    "        var[i] = var_hypo\n",
    "        ullh[i] = 0\n",
    "\n",
    "        for x in data_list:     \n",
    "            ullh[i] +=  log_func(x,var[i]) # Unbinned LLH function\n",
    "\n",
    "        if show_values and i % 10 == 0:\n",
    "            print(f\" {i:3d}:  p = {var_hypo:4.{digits}f}   log(ullh) = {ullh[i]:6.{digits}f}\")\n",
    "\n",
    "        # Search for minimum values of ullh:\n",
    "\n",
    "        if (ullh[i] < ullh_minval) :\n",
    "            ullh_minval = ullh[i]\n",
    "            ullh_minpos = var_hypo\n",
    "    \n",
    "    if show_values:\n",
    "        print(f'''\n",
    "    ________________________________________________________\n",
    "    --------------------------------------------------------\n",
    "                 Log Likelihood Sweep Results\n",
    "    --------------------------------------------------------\n",
    "    Minimum value of sweep:      {ullh_minval:.{digits}f}\n",
    "    Variable value at minimum:   {ullh_minpos:.{digits}f}\n",
    "    ________________________________________________________''')\n",
    "\n",
    "    return var, ullh, ullh_minval, ullh_minpos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='monte_carlo'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarlo(func, N_points, xmin = 0, xmax = 1, ymin = 0, ymax = 1, print_result=True, **kwdarg):\n",
    "    '''\n",
    "    Generate random number according to a pdf using Monte Carlo.\n",
    "    Inputs are:\n",
    "        - the pdf\n",
    "        - the number of points to be generated\n",
    "        - Ranges of the x and y values (optional)\n",
    "        - any additional arguments for the pdf (optional)    \n",
    "    '''\n",
    "    N_try = 0\n",
    "    x_accepted = np.zeros(N_points)\n",
    "    for i in range(N_points):\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            # Count the number of tries, to get efficiency/integral\n",
    "            N_try += 1   \n",
    "\n",
    "            # Range that f(x) is defined/wanted in:\n",
    "            x_test = np.random.uniform(xmin, xmax)  \n",
    "\n",
    "            # Upper bound for function values:\n",
    "            y_test = np.random.uniform(ymin, ymax)\n",
    "\n",
    "            if (y_test <= func(x_test, **kwdarg)):\n",
    "                break\n",
    "\n",
    "        x_accepted[i] = x_test\n",
    "        \n",
    "    # Efficiency\n",
    "    eff = N_points / N_try                        \n",
    "\n",
    "    # Error on efficiency (binomial)\n",
    "    eff_error = np.sqrt(eff * (1-eff) / N_try) \n",
    "\n",
    "    # Integral\n",
    "    integral =  eff * (xmax-xmin) * (ymax-ymin)\n",
    "\n",
    "    # Error on integral\n",
    "    eintegral = eff_error * (xmax-xmin) * (ymax-ymin)  \n",
    "    if print_result:\n",
    "        print(f'''\n",
    "    _____________________________________________________________\n",
    "    -------------------------------------------------------------\n",
    "                             Monte Carlo \n",
    "    -------------------------------------------------------------\n",
    "    Generation of random numbers according to the given pdf.\n",
    "    -------------------------------------------------------------\n",
    "    Intervals used to sample random numbers:\n",
    "    x in [{xmin}, {xmax}]\n",
    "    y in [{ymin}, {ymax}]\n",
    "    \n",
    "    Integral of the pdf is:  {integral:.4f} +/- {eintegral:.4f}\n",
    "    \n",
    "    Efficiency of the Accept/Reject method is:  {eff:.2%} +/- {eff_error:.2%}\n",
    "    _____________________________________________________________''')\n",
    "    return x_accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mc_sums'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_of_MC_sums(func, N_elements, N_points, xmin = 0, xmax = 1, ymin = 0, ymax = 1, print_result=False, **kwdarg):\n",
    "    '''\n",
    "    Generate an array of N_elements.\n",
    "    All elements are the sum of N_points random numbers generated according to a pdf using Monte Carlo.\n",
    "    Inputs are:\n",
    "        - the pdf\n",
    "        - the number of elements to be generated\n",
    "        - the number of points to be generated\n",
    "        - Ranges of the x and y values (optional)\n",
    "        - any additional arguments for the pdf (optional) \n",
    "    '''\n",
    "    u = np.zeros(N_elements)\n",
    "    for i in range(N_elements):\n",
    "        u[i] = MonteCarlo(func, N_points, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, print_result=print_result, **kwdarg).sum()\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mc_error'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_errorpropagation(func, N_exp, mu1, sig1, mu2, sig2, rho=0.0, get_data=False, get_values=False):\n",
    "    '''\n",
    "    Monte Carlo simulation of the error propagation of a function with 2 variables.\n",
    "    \n",
    "    mu1 and mu2 is the value of the variable. sig1 and sig2 is the uncertainties on the values.\n",
    "    \n",
    "    If both uncertainties have the same value the function can't do correlated \n",
    "    parameters as it would result in division by 0.\n",
    "    '''\n",
    "    result = None\n",
    "    if not (-1.0 <= rho <= 1.0): \n",
    "        raise ValueError(f\"Correlation factor not in interval [-1,1], as it is {rho12:6.2f}\")\n",
    "    if sig1 == sig2:\n",
    "        theta = 0\n",
    "    else:\n",
    "        theta = 0.5 * np.arctan( 2.0 * rho * sig1 * sig2 / ( np.square(sig1) - np.square(sig2) ) )\n",
    "\n",
    "    sigu = np.sqrt( np.abs( ((sig1*np.cos(theta)**2) - (sig2*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "    sigv = np.sqrt( np.abs( ((sig2*np.cos(theta)**2) - (sig1*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "\n",
    "    sigu = np.sqrt( np.abs( (((sig1*np.cos(theta))**2) - (sig2*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "    sigv = np.sqrt( np.abs( (((sig2*np.cos(theta))**2) - (sig1*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "\n",
    "    u = np.random.normal(0.0, sigu, N_exp)\n",
    "    v = np.random.normal(0.0, sigv, N_exp)\n",
    "\n",
    "    x1_all = mu1 + np.cos(theta)*u - np.sin(theta)*v\n",
    "    x2_all = mu2 + np.sin(theta)*u + np.cos(theta)*v\n",
    "\n",
    "    y_all = func(x1_all, x2_all)\n",
    "\n",
    "    y_mean, y_rms, y_unc = mean_no_unc(y_all, get_values=True)\n",
    "    \n",
    "    if get_data:\n",
    "        result = y_all\n",
    "    elif get_values:\n",
    "        result = y_mean, y_unc, y_rms\n",
    "    elif get_data and get_values:\n",
    "        result = y_all, y_mean, y_unc, y_rms\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='corr_matrix'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(x, y=None, rowvar=True, print_level=True):\n",
    "    '''\n",
    "    Calculates the correlation matrix between any number of variables \n",
    "    for a given data set.\n",
    "    \n",
    "    rowvar determines the direction the data set is read in. True if \n",
    "    each variable is a row, False if each variable is a column.\n",
    "    '''\n",
    "    corr_matrix = np.corrcoef(x, y=y, rowvar=rowvar)\n",
    "    if print_level == True:\n",
    "        print(f'''\n",
    "    ______________________________________________\n",
    "    ----------------------------------------------\n",
    "                 Correlation matrix\n",
    "    ----------------------------------------------''')\n",
    "        for row in corr_matrix:\n",
    "            print(f'    {row}')\n",
    "        print('    ______________________________________________')\n",
    "    \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calc_sep'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_separation(x, y):\n",
    "    '''\n",
    "    Calculate the seperation between two histograms.\n",
    "    '''\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    std_x = np.std(x, ddof=1)\n",
    "    std_y = np.std(y, ddof=1)\n",
    "    d = np.abs((mean_x - mean_y)) / np.sqrt(std_x**2 + std_y**2)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calc_roc'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ROC(hist1, hist2) :\n",
    "    '''\n",
    "    Calculate ROC curve from two histograms (hist1 is signal, hist2 is background).\n",
    "    '''\n",
    "\n",
    "    # First we extract the entries (y values) and the edges of the histograms\n",
    "    y_sig, x_sig_edges, _ = hist1 \n",
    "    y_bkg, x_bkg_edges, _ = hist2\n",
    "    \n",
    "    # Check that the two histograms have the same x edges:\n",
    "    if np.array_equal(x_sig_edges, x_bkg_edges) :\n",
    "        \n",
    "        # Extract the center positions (x values) of the bins (both signal or background works - equal binning)\n",
    "        x_centers = 0.5*(x_sig_edges[1:] + x_sig_edges[:-1])\n",
    "        \n",
    "        # Calculate the integral (sum) of the signal and background:\n",
    "        integral_sig = y_sig.sum()\n",
    "        integral_bkg = y_bkg.sum()\n",
    "    \n",
    "        # Initialize empty arrays for the True Positive Rate (TPR) and the False Positive Rate (FPR):\n",
    "        TPR = np.zeros_like(y_sig) # True positive rate (sensitivity)\n",
    "        FPR = np.zeros_like(y_sig) # False positive rate ()\n",
    "        \n",
    "        # Loop over all bins (x_centers) of the histograms and calculate TN, FP, FN, TP, FPR, and TPR for each bin:\n",
    "        for i, x in enumerate(x_centers): \n",
    "            \n",
    "            # The cut mask\n",
    "            cut = (x_centers < x)\n",
    "            \n",
    "            # True positive\n",
    "            TP = np.sum(y_sig[~cut]) / integral_sig    # True positives\n",
    "            FN = np.sum(y_sig[cut]) / integral_sig     # False negatives\n",
    "            TPR[i] = TP / (TP + FN)                    # True positive rate\n",
    "            \n",
    "            # True negative\n",
    "            TN = np.sum(y_bkg[cut]) / integral_bkg      # True negatives (background)\n",
    "            FP = np.sum(y_bkg[~cut]) / integral_bkg     # False positives\n",
    "            FPR[i] = FP / (FP + TN)                     # False positive rate            \n",
    "            \n",
    "        return FPR, TPR\n",
    "    \n",
    "    else:\n",
    "        AssertionError(\"Signal and Background histograms have different bins and ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='covar_offdiag'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariance_offdiag(X, Y):\n",
    "    '''\n",
    "    Calculate the off-diagonal value [var_i, var_j] in the covariance matrix.\n",
    "    '''\n",
    "    return np.cov(X, Y, ddof=1)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='covar_matrix'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_covar_matrix(data_list1, data_format=1, printlevel = False, n = 0):\n",
    "    '''\n",
    "    Calculate the covariance matrix for a data_list.\n",
    "    \n",
    "    The data_list could have two possible formats of the type [rows, columns].\n",
    "    Format type 1 is [data object, variable data].\n",
    "    Format type 2 is [variable data, data object].\n",
    "    \n",
    "    A data object is a flat array with one value of each variable.\n",
    "    Variable data is a flat array with all values measured for that variable.\n",
    "    \n",
    "    n dictates the text printed. Use n=0 to print the covariance matrix.\n",
    "    Use n=1 and n=2 to differentiate between covariance matrices when calculating Fisher coefficients.\n",
    "    '''\n",
    "    if data_format == 2:\n",
    "        data_list1 = data_list1.T\n",
    "        \n",
    "    cov_mat = np.zeros((len(data_list1[0]),len(data_list1[0])))\n",
    "    for ivar in range(len(data_list1[0])):\n",
    "        for jvar in range(len(data_list1[0])):\n",
    "            cov_mat[ivar, jvar] = get_covariance_offdiag(data_list1[:, ivar],data_list1[:, jvar])\n",
    "    if printlevel == True and n == 0:\n",
    "        print(f'''\n",
    "    ______________________________________________\n",
    "    ----------------------------------------------\n",
    "             Covariance matrix\n",
    "    ----------------------------------------------''')\n",
    "        for row in cov_mat:\n",
    "            print(f'    {row}')\n",
    "        print('    ______________________________________________')\n",
    "    if printlevel == True and n == 1:\n",
    "        print(f'''\n",
    "    ______________________________________________\n",
    "    ----------------------------------------------\n",
    "             Covariance matrix #1\n",
    "    ----------------------------------------------''')\n",
    "        for row in cov_mat:\n",
    "            print(f'    {row}')\n",
    "        print('    ______________________________________________')\n",
    "    if printlevel == True and n == 2:\n",
    "        print(f'''\n",
    "    ______________________________________________\n",
    "    ----------------------------------------------\n",
    "             Covariance matrix #2\n",
    "    ----------------------------------------------''')\n",
    "        for row in cov_mat:\n",
    "            print(f'    {row}')\n",
    "        print('    ______________________________________________')\n",
    "    return cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fisher_coef'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_coef(data_list1, data_list2, data_format=1, printlevel = False):\n",
    "    '''\n",
    "    Calculates Fisher coefficients for two data lists.\n",
    "    \n",
    "    The data_lists could have two possible formats of the type [rows, columns].\n",
    "    Format type 1 is [data object, variable data].\n",
    "    Format type 2 is [variable data, data object].\n",
    "    \n",
    "    A data object is a flat array with one value of each variable.\n",
    "    Variable data is a flat array with all values measured for that variable.\n",
    "    '''\n",
    "    if data_format == 2:\n",
    "        data_list1 = data_list1.T\n",
    "        data_list2 = data_list2.T\n",
    "        \n",
    "    if len(data_list1[0]) == len(data_list2[0]):\n",
    "        cov_mat1 = calc_covar_matrix(data_list1, printlevel = printlevel, n = 1)\n",
    "        cov_mat2 = calc_covar_matrix(data_list2, printlevel = printlevel, n = 2)\n",
    "        covmat_comb_inv = inv(cov_mat1 + cov_mat2)\n",
    "        mu_list1 = np.zeros(len(data_list1[0]))\n",
    "        mu_list2 = np.zeros(len(data_list1[0]))\n",
    "        for ivar in range(len(data_list1[0])):\n",
    "            var_list1 = data_list1[:, ivar]\n",
    "            var_list2 = data_list2[:, ivar]\n",
    "            mu_list1[ivar] = var_list1.mean()\n",
    "            mu_list2[ivar] = var_list2.mean()\n",
    "        wf = covmat_comb_inv.dot(mu_list1-mu_list2)\n",
    "        if printlevel == True:\n",
    "            print(f'''\n",
    "    _______________________________________________\n",
    "    -----------------------------------------------\n",
    "                 Fisher coefficients\n",
    "    -----------------------------------------------''')\n",
    "            for row in wf:\n",
    "                print(f'    {row}')\n",
    "            print('    _______________________________________________')\n",
    "        return wf\n",
    "    else:\n",
    "        print('Data lists do not have same dimensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fisher_descri'></a>\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_descri(data_list1, data_list2, data_format=1, printlevel = False):\n",
    "    '''\n",
    "    Calculates Fisher discriminants for data_list1 and data_list2.\n",
    "    \n",
    "    The data_lists could have two possible formats of the type [rows, columns].\n",
    "    Format type 1 is [data object, variable data].\n",
    "    Format type 2 is [variable data, data object].\n",
    "    \n",
    "    A data object is a flat array with one value of each variable.\n",
    "    Variable data is a flat array with all values measured for that variable.\n",
    "    '''\n",
    "    if data_format == 2:\n",
    "        data_list1 = data_list1.T\n",
    "        data_list2 = data_list2.T\n",
    "    \n",
    "    prik1 = []\n",
    "    prik2 = []\n",
    "    wf = fisher_coef(data_list1, data_list2, printlevel = printlevel)\n",
    "    for ivar in range(len(data_list1[0])):\n",
    "        var_list1 = data_list1[:, ivar]\n",
    "        var_list2 = data_list2[:, ivar]\n",
    "        wf_element = wf[ivar]\n",
    "        prik1.append(wf_element*var_list1)\n",
    "        prik2.append(wf_element*var_list2)\n",
    "    fisher_descri1 = np.zeros(len(prik1[0]))\n",
    "    fisher_descri2 = np.zeros(len(prik2[0]))\n",
    "    for i in range(len(prik1[0])):\n",
    "        fisher_element1 = 0\n",
    "        for j in range(len(prik1)):\n",
    "            if len(prik1[0]) == len(prik1[j]):\n",
    "                fisher_element1 += prik1[j][i]\n",
    "            else:\n",
    "                print('Variable lists do not have same dimensions')\n",
    "                return None\n",
    "        fisher_descri1[i] = fisher_element1\n",
    "    for k in range(len(prik2[0])):\n",
    "        fisher_element2 = 0\n",
    "        for l in range(len(prik2)):\n",
    "            if len(prik2[0]) == len(prik2[l]):\n",
    "                fisher_element2 += prik2[l][k]\n",
    "            else:\n",
    "                print('Variable lists do not have same dimensions')\n",
    "                return None\n",
    "        fisher_descri2[k] = fisher_element2\n",
    "    fisher_descri1 = np.array(fisher_descri1)\n",
    "    fisher_descri2 = np.array(fisher_descri2)\n",
    "    return fisher_descri1, fisher_descri2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions from other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dist_func'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistical functions\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------\n",
    "                                     Binomial\n",
    "------------------------------------------------------------------------------------\n",
    "stats.binom\n",
    "\n",
    "Most useful methods (used by adding \".<method_name>\":\n",
    "    - pmf                                 (Probability mass function)\n",
    "    - cdf                                 (Cumulative distribution function)\n",
    "    - sf                                  (Survival function)\n",
    "    - ppf                                 (Percent point function)\n",
    "    - isf                                 (Inverse survival function)\n",
    "    - median                              (Median of the distribution)\n",
    "    - mean                                (Mean of the distribution)\n",
    "    - var                                 (Variance of the distribution)\n",
    "    - std                                 (Standard deviation of the distribution)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html\n",
    "-------------------------------------------------------------------------------------\n",
    "                                       Poisson\n",
    "-------------------------------------------------------------------------------------\n",
    "stats.poisson\n",
    "\n",
    "Most useful methods (used by adding \".<method_name>\":\n",
    "    - pmf                                 (Probability mass function)\n",
    "    - cdf                                 (Cumulative distribution function)\n",
    "    - sf                                  (Survival function)\n",
    "    - ppf                                 (Percent point function)\n",
    "    - isf                                 (Inverse survival function)\n",
    "    - median                              (Median of the distribution)\n",
    "    - mean                                (Mean of the distribution)\n",
    "    - var                                 (Variance of the distribution)\n",
    "    - std                                 (Standard deviation of the distribution)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html\n",
    "-------------------------------------------------------------------------------------\n",
    "                                       Gaussian\n",
    "-------------------------------------------------------------------------------------\n",
    "stats.norm\n",
    "\n",
    "Most useful methods (used by adding \".<method_name>\":\n",
    "    - pdf                                 (Probability density function)\n",
    "    - cdf                                 (Cumulative distribution function)\n",
    "    - sf                                  (Survival function)\n",
    "    - ppf                                 (Percent point function)\n",
    "    - isf                                 (Inverse survival function)\n",
    "    - median                              (Median of the distribution)\n",
    "    - mean                                (Mean of the distribution)\n",
    "    - var                                 (Variance of the distribution)\n",
    "    - std                                 (Standard deviation of the distribution)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "-------------------------------------------------------------------------------------\n",
    "                                       ChiSquare\n",
    "-------------------------------------------------------------------------------------\n",
    "stats.chi2\n",
    "\n",
    "Most useful methods (used by adding \".<method_name>\":\n",
    "    - pdf                                 (Probability density function)\n",
    "    - cdf                                 (Cumulative distribution function)\n",
    "    - sf                                  (Survival function)\n",
    "    - ppf                                 (Percent point function)\n",
    "    - isf                                 (Inverse survival function)\n",
    "    - median                              (Median of the distribution)\n",
    "    - mean                                (Mean of the distribution)\n",
    "    - var                                 (Variance of the distribution)\n",
    "    - std                                 (Standard deviation of the distribution)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html\n",
    "-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='other_func'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful functions\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "              Make an array of numbers equally spaced in an interval\n",
    "--------------------------------------------------------------------------------------\n",
    "np.linspace(start, stop, N_steps)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html\n",
    "--------------------------------------------------------------------------------------\n",
    "                           Make a list into a numpy array\n",
    "--------------------------------------------------------------------------------------\n",
    "np.array(list)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\n",
    "--------------------------------------------------------------------------------------\n",
    "                        Make a numpy array full of zeroes\n",
    "--------------------------------------------------------------------------------------\n",
    "         Array of given size\n",
    "----------------------------------------\n",
    "np.zeros(size)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html\n",
    "----------------------------------------\n",
    " Array of same size as other list/array\n",
    "----------------------------------------\n",
    "np.zeros_like(list_or_array)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "--------------------------------------------------------------------------------------\n",
    "                Get array of random numbers with equal probability\n",
    "--------------------------------------------------------------------------------------\n",
    "            Random floats\n",
    "----------------------------------------\n",
    "np.random.uniform(low, high, size)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.uniform.html\n",
    "----------------------------------------\n",
    "            Random integer\n",
    "----------------------------------------\n",
    "np.random.randint(low, high, size)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.randint.html\n",
    "--------------------------------------------------------------------------------------\n",
    "                                 Set the random seed\n",
    "--------------------------------------------------------------------------------------\n",
    "np.random.seed(int)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.seed.html\n",
    "--------------------------------------------------------------------------------------\n",
    "                    Combine functions to a piecewise function\n",
    "--------------------------------------------------------------------------------------\n",
    "np.piecewise(x, condlist, funclist)\n",
    "\n",
    "Documentation for the function can be found at: \n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.piecewise.html\n",
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting_template'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting template\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig1, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "\n",
    "# Insert things to be plotted here\n",
    "\n",
    "ax1.set_title('Sample Text')\n",
    "ax1.set_xlabel('Sample Text')\n",
    "ax1.set_ylabel('Sample Text')\n",
    "\n",
    "# Insert further formatting here\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='common_plots'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common plots\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------\n",
    "                                             Line/scatter plots\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "Simple plot of a line\n",
    "----------------------\n",
    "ax1.plot(x, y, label='Sample Text')\n",
    "\n",
    "----------------------\n",
    "Simple plot of points\n",
    "----------------------\n",
    "ax1.scatter(x, y, label='Sample Text')\n",
    "\n",
    "--------------------------------------------------------------------------------------\n",
    "Specific version for plotting functions with parameters determined by a ChiSquare Fit\n",
    "--------------------------------------------------------------------------------------\n",
    "x_func = np.linspace(xmin, xmax, n_points)\n",
    "ax1.plot(x_func, function(x_func,*minuit_obj.args), label='Sample Text')\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "                                              1D histograms\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "Simple histogram from data\n",
    "---------------------------\n",
    "ax1.hist(data, bins=Nbins, range=(xmin,xmax), histtype = 'step', label='Sample Text')\n",
    "\n",
    "--------------------------------------\n",
    "Simple histogram from bins and counts\n",
    "--------------------------------------\n",
    "ax1.bar(bin_centers, counts, fill=False, label='Sample Text')\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "                                           Plots with errorbars\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "Plot with errorbars\n",
    "---------------------\n",
    "ax1.errorbar(x, y, xerr=x_unc, yerr=y_unc, label='Sample Text')\n",
    "\n",
    "---------------------------------------------------------\n",
    "Specific version for plotting histograms with bin errors\n",
    "---------------------------------------------------------\n",
    "ax1.errorbar(bin_centers, counts, sy, marker='.', drawstyle='steps-mid', label='Sample Text')\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "                                              2D histograms\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "2D histogram from data\n",
    "-----------------------\n",
    "hist2d = ax1.hist2d(x_data, y_data, bins=Nbins, range=[(xmin, xmax), (ymin,ymax)], cmin=1, alpha=0.8)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "                                              Plot ROC-curve\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "ROC-curve from output of calc_ROC\n",
    "----------------------------------\n",
    "ax1.plot([0,1],[0,1], ':', color = 'blue', label = 'Random Guess') # Diagonal Line\n",
    "ax1.plot(FPR, TPR, '-', label = 'ROC')\n",
    "\n",
    "ax1.set_xlabel('False Positive Rate (Background Efficiency)')\n",
    "ax1.set_ylabel('True Positive Rate (Signal Efficiency)')\n",
    "ax1.set_xlim((0,1))\n",
    "ax1.set_ylim((0,1))\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "                                     Most common formatting commands\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "linewidth =        |  Takes a number as argument. Typical value is 1, 2 or 3\n",
    "\n",
    "color =            |  Takes a string as argument. Typical colors blue (b), red (r), green (g), black (k).\n",
    "                   |  All colors can be found here https://www.w3schools.com/colors/colors_groups.asp\n",
    "                   \n",
    "marker =           |  Takes a string as argument. Typical marker types point (.), dot (o), triangle (^),\n",
    "                   |  square (s), cross (x), plus (+).\n",
    "\n",
    "alpha =            |  Takes a number between 0 and 1 as argument. Controls the transparency of an object.\n",
    "\n",
    "zorder =           |  Takes an int as argument. Controls the z-ordering of objects, highest zorder in \n",
    "                   |  front and lowest in the back.\n",
    "\n",
    "label =            |  String used as label for the plot element. Specifically for strings used as labels\n",
    "                   |  LaTex math formatting can be used to make symbols and formulas etc.\n",
    "                   |  To use LaTex math formatting use $<insert_math_or_symbol_here>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='common_format'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common axes/figure formatting\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "                    Control plotting range\n",
    "----------------------------------------------------------------\n",
    "\n",
    "ax1.set_xlim((xmin,xmax))\n",
    "ax1.set_ylim((ymin,ymax))\n",
    "----------------------------------------------------------------\n",
    "                     Make axis logarithmic\n",
    "----------------------------------------------------------------\n",
    "\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "----------------------------------------------------------------\n",
    "                Manually define the shown ticks\n",
    "----------------------------------------------------------------\n",
    "\n",
    "ax1.xaxis.set_ticks([])\n",
    "ax1.yaxis.set_ticks([])\n",
    "----------------------------------------------------------------\n",
    "                   Make custom tick labels\n",
    "----------------------------------------------------------------\n",
    "\n",
    "ax1.xaxis.set_ticklabels([])\n",
    "ax1.yaxis.set_ticklabels([])\n",
    "----------------------------------------------------------------\n",
    "              Draw vertical or horizontal lines\n",
    "----------------------------------------------------------------\n",
    "\n",
    "ax1.axvline(x=)\n",
    "ax1.axhline(y=)\n",
    "----------------------------------------------------------------\n",
    "                Make a colorbar for 2d figures\n",
    "----------------------------------------------------------------\n",
    "\n",
    "fig1.colorbar(hist2d[3], ax=ax1)\n",
    "----------------------------------------------------------------\n",
    "                      Add text to figure\n",
    "----------------------------------------------------------------\n",
    "\n",
    "Print a dict of variable names and \n",
    "values on plot\n",
    "\n",
    "d = {'Param1':   Param1_val,\n",
    "     'Param2':   Param2_val,\n",
    "     'Param3':   Param3_val,\n",
    "     }\n",
    "\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(rel_pos_x, rel_pos_y, text, ax1, fontsize=14)\n",
    "\n",
    "Example dict:\n",
    "d = {'Chi2':     chi2,\n",
    "     'Ndof':      ndof,\n",
    "     'Prob':     prob,\n",
    "    }\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='common_save'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save commands for most common file formats \n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------\n",
    "Save as .jpg\n",
    "\n",
    "plt.savefig('example.jpg',bbox_inches='tight',format='jpg', dpi=1000)\n",
    "----------------------------------------------------------------------\n",
    "Save as .png\n",
    "\n",
    "plt.savefig('example.png',bbox_inches='tight',format='png', dpi=1000)\n",
    "----------------------------------------------------------------------\n",
    "Save as .eps\n",
    "(vector format allowing for \"infinite\" resolution)\n",
    "\n",
    "plt.savefig('example.eps',bbox_inches='tight',format='eps', dpi=1000)\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot_inspiration'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of inspiration for plotting\n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python4astronomers.github.io/plotting/advanced.html\n",
    "\n",
    "https://python-graph-gallery.com/matplotlib/\n",
    "\n",
    "https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/\n",
    "\n",
    "https://matplotlib.org/gallery.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Functions integration\n",
    "### Author\n",
    " - Christian Michelsen, NBI, 2018\n",
    " \n",
    "[To the Table of Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='external_functions'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(value, decimals):\n",
    "    \"\"\" \n",
    "    Checks the type of a variable and formats it accordingly.\n",
    "    Floats has 'decimals' number of decimals.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(value, (float, np.float)):\n",
    "        return f'{value:.{decimals}f}'\n",
    "    elif isinstance(value, (int, np.integer)):\n",
    "        return f'{value:d}'\n",
    "    else:\n",
    "        return f'{value}'\n",
    "\n",
    "def values_to_string(values, decimals):\n",
    "    \"\"\" \n",
    "    Loops over all elements of 'values' and returns list of strings\n",
    "    with proper formating according to the function 'format_value'. \n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    for value in values:\n",
    "        if isinstance(value, list):\n",
    "            tmp = [format_value(val, decimals) for val in value]\n",
    "            res.append(f'{tmp[0]} +/- {tmp[1]}')\n",
    "        else:\n",
    "            res.append(format_value(value, decimals))\n",
    "    return res\n",
    "\n",
    "def len_of_longest_string(s):\n",
    "    \"\"\" Returns the length of the longest string in a list of strings \"\"\"\n",
    "    return len(max(s, key=len))\n",
    "\n",
    "def nice_string_output(d, extra_spacing=5, decimals=3):\n",
    "    \"\"\" \n",
    "    Takes a dictionary d consisting of names and values to be properly formatted.\n",
    "    Makes sure that the distance between the names and the values in the printed\n",
    "    output has a minimum distance of 'extra_spacing'. One can change the number\n",
    "    of decimals using the 'decimals' keyword.  \n",
    "    \"\"\"\n",
    "    \n",
    "    names = d.keys()\n",
    "    max_names = len_of_longest_string(names)\n",
    "    \n",
    "    values = values_to_string(d.values(), decimals=decimals)\n",
    "    max_values = len_of_longest_string(values)\n",
    "    \n",
    "    string = \"\"\n",
    "    for name, value in zip(names, values):\n",
    "        spacing = extra_spacing + max_values + max_names - len(name) - 1 \n",
    "        string += \"{name:s} {value:>{spacing}} \\n\".format(name=name, value=value, spacing=spacing)\n",
    "    return string[:-2]\n",
    "\n",
    "def add_text_to_ax(x_coord, y_coord, string, ax, fontsize=12, color='k'):\n",
    "    \"\"\" Shortcut to add text to an ax with proper font. Relative coords.\"\"\"\n",
    "    ax.text(x_coord, y_coord, string, family='monospace', fontsize=fontsize,\n",
    "            transform=ax.transAxes, verticalalignment='top', color=color)\n",
    "    return None\n",
    "\n",
    "# =============================================================================\n",
    "#  Probfit replacement\n",
    "# =============================================================================\n",
    "\n",
    "from iminuit.util import make_func_code\n",
    "from iminuit import describe #, Minuit,\n",
    "\n",
    "def set_var_if_None(var, x):\n",
    "    if var is not None:\n",
    "        return np.array(var)\n",
    "    else: \n",
    "        return np.ones_like(x)\n",
    "    \n",
    "def compute_f(f, x, *par):\n",
    "    \n",
    "    try:\n",
    "        return f(x, *par)\n",
    "    except ValueError:\n",
    "        return np.array([f(xi, *par) for xi in x])\n",
    "\n",
    "class Chi2Regression:  # override the class with a better one\n",
    "    \n",
    "    def __init__(self, f, x, y, sy=None, weights=None):\n",
    "        \n",
    "        self.f = f  # model predicts y for given x\n",
    "        self.x = np.array(x)\n",
    "        self.y = np.array(y)\n",
    "        \n",
    "        self.sy = set_var_if_None(sy, self.x)\n",
    "        self.weights = set_var_if_None(weights, self.x)\n",
    "        self.func_code = make_func_code(describe(self.f)[1:])\n",
    "\n",
    "    def __call__(self, *par):  # par are a variable number of model parameters\n",
    "        \n",
    "        # compute the function value\n",
    "        f = compute_f(self.f, self.x, *par)\n",
    "        \n",
    "        # compute the chi2-value\n",
    "        chi2 = np.sum(self.weights*(self.y - f)**2/self.sy**2)\n",
    "        \n",
    "        return chi2\n",
    "\n",
    "def simpson38(f, edges, bw, *arg):\n",
    "    \n",
    "    yedges = f(edges, *arg)\n",
    "    left38 = f((2.*edges[1:]+edges[:-1]) / 3., *arg)\n",
    "    right38 = f((edges[1:]+2.*edges[:-1]) / 3., *arg)\n",
    "    \n",
    "    return bw / 8.*( np.sum(yedges)*2.+np.sum(left38+right38)*3. - (yedges[0]+yedges[-1]) ) #simpson3/8\n",
    "\n",
    "def integrate1d(f, bound, nint, *arg):\n",
    "    \"\"\"\n",
    "    compute 1d integral\n",
    "    \"\"\"\n",
    "    edges = np.linspace(bound[0], bound[1], nint+1)\n",
    "    bw = edges[1] - edges[0]\n",
    "    \n",
    "    return simpson38(f, edges, bw, *arg)\n",
    "\n",
    "class UnbinnedLH:  # override the class with a better one\n",
    "    \n",
    "    def __init__(self, f, data, weights=None, badvalue=-100000, extended=False, extended_bound=None, extended_nint=100):\n",
    "        \n",
    "        self.f = f  # model predicts PDF for given x\n",
    "        self.data = np.array(data)\n",
    "        self.weights = set_var_if_None(weights, self.data)\n",
    "        self.bad_value = badvalue\n",
    "        \n",
    "        self.extended = extended\n",
    "        self.extended_bound = extended_bound\n",
    "        self.extended_nint = extended_nint\n",
    "        if extended and extended_bound is None:\n",
    "            self.extended_bound = (np.min(data), np.max(data))\n",
    "\n",
    "        \n",
    "        self.func_code = make_func_code(describe(self.f)[1:])\n",
    "\n",
    "    def __call__(self, *par):  # par are a variable number of model parameters\n",
    "        \n",
    "        logf = np.zeros_like(self.data)\n",
    "        \n",
    "        # compute the function value\n",
    "        f = compute_f(self.f, self.data, *par)\n",
    "    \n",
    "        # find where the PDF is 0 or negative (unphysical)        \n",
    "        mask_f_positive = (f>0)\n",
    "\n",
    "        # calculate the log of f everyhere where f is positive\n",
    "        logf[mask_f_positive] = np.log(f[mask_f_positive]) * self.weights[mask_f_positive] \n",
    "        \n",
    "        # set everywhere else to badvalue\n",
    "        logf[~mask_f_positive] = self.bad_value\n",
    "        \n",
    "        # compute the sum of the log values: the LLH\n",
    "        llh = -np.sum(logf)\n",
    "        \n",
    "        if self.extended:\n",
    "            extended_term = integrate1d(self.f, self.extended_bound, self.extended_nint, *par)\n",
    "            llh += extended_term\n",
    "        \n",
    "        return llh\n",
    "    \n",
    "    def default_errordef(self):\n",
    "        return 0.5\n",
    "\n",
    "class BinnedLH:  # override the class with a better one\n",
    "    \n",
    "    def __init__(self, f, data, bins=40, weights=None, weighterrors=None, bound=None, badvalue=1000000, extended=False, use_w2=False, nint_subdiv=1):\n",
    "        \n",
    "        self.weights = set_var_if_None(weights, data)\n",
    "\n",
    "\n",
    "        self.f = f\n",
    "        self.use_w2 = use_w2\n",
    "        self.extended = extended\n",
    "\n",
    "        if bound is None: \n",
    "            bound = (np.min(data), np.max(data))\n",
    "\n",
    "        self.mymin, self.mymax = bound\n",
    "\n",
    "        h, self.edges = np.histogram(data, bins, range=bound, weights=weights)\n",
    "        \n",
    "        self.bins = bins\n",
    "        self.h = h\n",
    "        self.N = np.sum(self.h)\n",
    "\n",
    "        if weights is not None:\n",
    "            if weighterrors is None:\n",
    "                self.w2, _ = np.histogram(data, bins, range=bound, weights=weights**2)\n",
    "            else:\n",
    "                self.w2, _ = np.histogram(data, bins, range=bound, weights=weighterrors**2)\n",
    "        else:\n",
    "            self.w2, _ = np.histogram(data, bins, range=bound, weights=None)\n",
    "\n",
    "\n",
    "        \n",
    "        self.badvalue = badvalue\n",
    "        self.nint_subdiv = nint_subdiv\n",
    "        \n",
    "        \n",
    "        self.func_code = make_func_code(describe(self.f)[1:])\n",
    "        self.ndof = np.sum(self.h > 0) - (self.func_code.co_argcount - 1)\n",
    "        \n",
    "\n",
    "    def __call__(self, *par):  # par are a variable number of model parameters\n",
    "\n",
    "        # ret = compute_bin_lh_f(self.f, self.edges, self.h, self.w2, self.extended, self.use_w2, self.badvalue, *par)\n",
    "        ret = compute_bin_lh_f2(self.f, self.edges, self.h, self.w2, self.extended, self.use_w2, self.nint_subdiv, *par)\n",
    "        \n",
    "        return ret\n",
    "\n",
    "\n",
    "    def default_errordef(self):\n",
    "        return 0.5\n",
    "\n",
    "import warnings\n",
    "\n",
    "def xlogyx(x, y):\n",
    "    \n",
    "    #compute x*log(y/x) to a good precision especially when y~x\n",
    "    \n",
    "    if x<1e-100:\n",
    "        warnings.warn('x is really small return 0')\n",
    "        return 0.\n",
    "    \n",
    "    if x<y:\n",
    "        return x*np.log1p( (y-x) / x )\n",
    "    else:\n",
    "        return -x*np.log1p( (x-y) / y )\n",
    "\n",
    "#compute w*log(y/x) where w < x and goes to zero faster than x\n",
    "def wlogyx(w, y, x):\n",
    "    if x<1e-100:\n",
    "        warnings.warn('x is really small return 0')\n",
    "        return 0.\n",
    "    if x<y:\n",
    "        return w*np.log1p( (y-x) / x )\n",
    "    else:\n",
    "        return -w*np.log1p( (x-y) / y )\n",
    "\n",
    "def compute_bin_lh_f2(f, edges, h, w2, extended, use_sumw2, nint_subdiv, *par):\n",
    "    \n",
    "    N = np.sum(h)\n",
    "    n = len(edges)\n",
    "\n",
    "    ret = 0.\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        th = h[i]\n",
    "        tm = integrate1d(f, (edges[i], edges[i+1]), nint_subdiv, *par)\n",
    "        \n",
    "        if not extended:\n",
    "            if not use_sumw2:\n",
    "                ret -= xlogyx(th, tm*N) + (th-tm*N)\n",
    "\n",
    "            else:\n",
    "                if w2[i]<1e-200: \n",
    "                    continue\n",
    "                tw = w2[i]\n",
    "                factor = th/tw\n",
    "                ret -= factor*(wlogyx(th,tm*N,th)+(th-tm*N))\n",
    "        else:\n",
    "            if not use_sumw2:\n",
    "                ret -= xlogyx(th,tm)+(th-tm)\n",
    "            else:\n",
    "                if w2[i]<1e-200: \n",
    "                    continue\n",
    "                tw = w2[i]\n",
    "                factor = th/tw\n",
    "                ret -= factor*(wlogyx(th,tm,th)+(th-tm))\n",
    "\n",
    "    return ret\n",
    "\n",
    "def compute_bin_lh_f(f, edges, h, w2, extended, use_sumw2, badvalue, *par):\n",
    "    \n",
    "    mask_positive = (h>0)\n",
    "    \n",
    "    N = np.sum(h)\n",
    "    midpoints = (edges[:-1] + edges[1:]) / 2\n",
    "    b = np.diff(edges)\n",
    "    \n",
    "    midpoints_pos = midpoints[mask_positive]\n",
    "    b_pos = b[mask_positive]\n",
    "    h_pos = h[mask_positive]\n",
    "    \n",
    "    if use_sumw2:\n",
    "        warnings.warn('use_sumw2 = True: is not yet implemented, assume False ')\n",
    "        s = np.ones_like(midpoints_pos)\n",
    "        pass\n",
    "    else: \n",
    "        s = np.ones_like(midpoints_pos)\n",
    "\n",
    "    \n",
    "    E_pos = f(midpoints_pos, *par) * b_pos\n",
    "    if not extended:\n",
    "        E_pos = E_pos * N\n",
    "        \n",
    "    E_pos[E_pos<0] = badvalue\n",
    "    \n",
    "    ans = -np.sum( s*( h_pos*np.log( E_pos/h_pos ) + (h_pos-E_pos) ) )\n",
    "\n",
    "    return ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
